{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c9363a-bb96-42b0-ba8c-382a830f8ef4",
   "metadata": {},
   "source": [
    "# **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9eab9b5-7537-4f37-8511-c2dd48a923ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import joblib\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61df53-13b7-4d89-91f7-65ae803bd85b",
   "metadata": {},
   "source": [
    "# **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5424b54a-12dc-451b-9ffd-6aa6a9e5f4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nia Devi</td>\n",
       "      <td>4 bintang</td>\n",
       "      <td>Dari sblm lahir, lahiran trs baby juga di rawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>titania purnamasari</td>\n",
       "      <td>1 bintang</td>\n",
       "      <td>Gedung elit, parkir di basement sulit. Baru am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Farid Add</td>\n",
       "      <td>5 bintang</td>\n",
       "      <td>Sungguh luar biasa bagi saya untuk pelayanan t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susi Mashanafi</td>\n",
       "      <td>1 bintang</td>\n",
       "      <td>Tes napza disini, udah selesai tinggal nunggu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basuki Dwi Putranto</td>\n",
       "      <td>5 bintang</td>\n",
       "      <td>Selamat atas telah beroperasinya Gedung Baru K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Nama     Rating  \\\n",
       "0             Nia Devi  4 bintang   \n",
       "1  titania purnamasari  1 bintang   \n",
       "2            Farid Add  5 bintang   \n",
       "3       Susi Mashanafi  1 bintang   \n",
       "4  Basuki Dwi Putranto  5 bintang   \n",
       "\n",
       "                                              Ulasan  \n",
       "0  Dari sblm lahir, lahiran trs baby juga di rawa...  \n",
       "1  Gedung elit, parkir di basement sulit. Baru am...  \n",
       "2  Sungguh luar biasa bagi saya untuk pelayanan t...  \n",
       "3  Tes napza disini, udah selesai tinggal nunggu ...  \n",
       "4  Selamat atas telah beroperasinya Gedung Baru K...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(\"dataset/final-dataset.csv\", dtype=str) \n",
    "rs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ade4b-17bf-4cc1-accf-890deffe9b8f",
   "metadata": {},
   "source": [
    "# **3. Memahami Struktur Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a51b2ba2-9248-4973-85c5-f44dad9e627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3461 entries, 0 to 3460\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Nama    3461 non-null   object\n",
      " 1   Rating  3461 non-null   object\n",
      " 2   Ulasan  3461 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 81.2+ KB\n"
     ]
    }
   ],
   "source": [
    "rs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e56da-f255-430d-a898-f4cd46070548",
   "metadata": {},
   "source": [
    "# **4. Mengecheck data kosong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d37b662-9df5-4ba7-8322-d982f65abc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nama      0\n",
       "Rating    0\n",
       "Ulasan    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mengecheck data hilang\n",
    "rs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b62dcd-456f-410c-a526-f94a40d3dea5",
   "metadata": {},
   "source": [
    "# **5. Ekstraksi fitur dan pelabelan data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcd42d27-d0ad-4578-a3e5-e1e5797b4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\03ann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\03ann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61b9b164-dc3b-4975-b8d7-cf857fa217d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_rating(rating):\n",
    "    if pd.isna(rating) or rating.strip() == \"\":  \n",
    "        return None\n",
    "    angka = re.findall(r\"\\d+\", rating) \n",
    "    return int(angka[0]) if angka else None \n",
    "\n",
    "rs[\"Rating\"] = rs[\"Rating\"].astype(str).apply(clean_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d8c4930-5f49-4c56-8813-b649b06334cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan rating dalam bentuk string dulu\n",
    "rs[\"Rating\"] = rs[\"Rating\"].astype(str)\n",
    "\n",
    "# Ekstrak angka dari string \"5 bintang\", \"2 bintang\", dst\n",
    "rs[\"Rating\"] = rs[\"Rating\"].str.extract('(\\d)').astype(float)\n",
    "\n",
    "# Label sentimen\n",
    "def label_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return \"Positif\"\n",
    "    elif rating == 3:\n",
    "        return \"Netral\"\n",
    "    else:\n",
    "        return \"Negatif\"\n",
    "\n",
    "rs[\"Sentimen\"] = rs[\"Rating\"].apply(label_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8f80279-ac46-4926-81b6-f4275ccff594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimen\n",
      "Negatif    1353\n",
      "Positif    1347\n",
      "Netral      761\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rs[\"Sentimen\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de32c77f-1cca-4056-a6d6-30379705ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "1.0    1353\n",
      "5.0    1012\n",
      "3.0     761\n",
      "4.0     335\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rs[\"Rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81281d36-08a0-42d2-80d4-3cf0db21dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Ulasan  \\\n",
      "2662  Pelayanannya buruk sekali, pindah ke gedung ba...   \n",
      "1054  Pelayanannya buruk sekali, pindah ke gedung ba...   \n",
      "1063  Kami sadar hanya pasien kelas 3 PBI. Tapi kami...   \n",
      "214   Pelayanannya buruk sekali, pindah ke gedung ba...   \n",
      "2644  Selamat atas telah beroperasinya Gedung Baru K...   \n",
      "\n",
      "                                           Ulasan_Clean  \n",
      "2662  pelayanannya buruk_sekali pindah ke gedung bar...  \n",
      "1054  pelayanannya buruk_sekali pindah ke gedung bar...  \n",
      "1063  kami sadar hanya pasien kelas pbi tapi kami ti...  \n",
      "214   pelayanannya buruk_sekali pindah ke gedung bar...  \n",
      "2644  selamat atas telah beroperasinya gedung baru k...  \n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk membersihkan teks\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "    # Normalisasi slang / kata tidak baku\n",
    "    slang_map = {\n",
    "        \"ga\": \"tidak\",\n",
    "        \"gak\": \"tidak\",\n",
    "        \"nggak\": \"tidak\",\n",
    "        \"ngga\": \"tidak\",\n",
    "        \"cuman\": \"cuma\",\n",
    "        \"udh\": \"sudah\",\n",
    "        \"dr\": \"dari\",\n",
    "        \"bgt\": \"banget\",\n",
    "    }\n",
    "    for slang, formal in slang_map.items():\n",
    "        text = re.sub(rf'\\b{slang}\\b', formal, text)\n",
    "\n",
    "    # Gabungkan frasa negasi umum\n",
    "    negation_patterns = [\n",
    "        (r'\\btidak nyaman\\b', 'tidak_nyaman'),\n",
    "        (r'\\btidak enak\\b', 'tidak_enak'),\n",
    "        (r'\\btidak bagus\\b', 'tidak_bagus'),\n",
    "        (r'\\btidak bersih\\b', 'tidak_bersih'),\n",
    "        (r'\\btidak ramah\\b', 'tidak_ramah'),\n",
    "        (r'\\btidak kelar\\b', 'tidak_kelar'),\n",
    "        (r'\\btidak jelas\\b', 'tidak_jelas'),\n",
    "        (r'\\bburuk sekali\\b', 'buruk_sekali'),\n",
    "        (r'\\bjangan ke sini\\b', 'jangan_ke_sini'),\n",
    "    ]\n",
    "\n",
    "    for pattern, replacement in negation_patterns:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "rs[\"Ulasan_Clean\"] = rs[\"Ulasan\"].astype(str).apply(clean_text)\n",
    "print(rs[[\"Ulasan\", \"Ulasan_Clean\"]].sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73893d31-a59f-4bef-aac1-b4990559b503",
   "metadata": {},
   "source": [
    "# *Tokenisasi Teks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83bcfff3-aacb-436f-897d-ecc516c2908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nama', 'Rating', 'Ulasan', 'Sentimen', 'Ulasan_Clean'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fafaeaf7-0822-490d-bd7f-0c4434e880fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6  63  64  65  66  67  15   2  51   2  68   6  69  37   3  70  71  42\n",
      "   46  72  73  74  75  76  12  77  78  18  13   4   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  7  79  14   2  80  81  10  82  83  14   2   7  10  56  84   3  53  85\n",
      "   43  41  14  86  47  57  87  88   4   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 26  20  21  89  27  12   9  28   2  22  90  23  29   6  91  54  92  27\n",
      "   93  94   5  95  96  44  97   9   8  26  20  21  98  99   4   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [100 101 102 103 104 105 106 107   8  30   3 108  30  55  48 109  34   3\n",
      "  110  15 111 112 113 114 115   4   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 58  40 116 117   7  10 118 119  39  49   9   8 120  12 121  59 122   5\n",
      "   23  28   2 123   5 124   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(rs[\"Ulasan_Clean\"]) # Melatih tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "# Konversi teks menjadi urutan angka\n",
    "sequences = tokenizer.texts_to_sequences(rs[\"Ulasan_Clean\"])\n",
    "# Padding sequences agar memiliki panjang yang sama\n",
    "max_length = 50  # Panjang maksimum ulasan\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\", dtype=\"int32\")\n",
    "vocab_size = 5000\n",
    "# Cek hasil tokenisasi\n",
    "print(padded_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8720ac44-f1df-48b9-82c2-2b1a93543b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'di': 2, 'tidak': 3, '…': 4, 'dan': 5, 'dari': 6, 'gedung': 7, 'yang': 8, 'pelayanan': 9, 'baru': 10, 'dengan': 11, 'untuk': 12, 'pasien': 13, 'parkir': 14, 'juga': 15, 'kami': 16, 'ada': 17, 'ke': 18, 'hanya': 19, 'luar': 20, 'biasa': 21, 'bagian': 22, 'anak': 23, 'saja': 24, 'antrian': 25, 'sungguh': 26, 'saya': 27, 'terutama': 28, 'karena': 29, 'katanya': 30, 'ramah': 31, 'pelayanannya': 32, 'ruang': 33, 'jam': 34, 'saat': 35, 'staf': 36, 'fasilitas': 37, 'informasi': 38, 'dapat': 39, 'atas': 40, 'petugas': 41, 'beberapa': 42, 'jalan': 43, 'semua': 44, 'ac': 45, 'dokter': 46, 'orang': 47, 'menit': 48, 'memberikan': 49, 'bersih': 50, 'rawat': 51, 'banyak': 52, 'jelas': 53, 'sampai': 54, 'biasanya': 55, 'motor': 56, 'duduk': 57, 'selamat': 58, 'kesehatan': 59, 'perlu': 60, 'sama': 61, 'kelas': 62, 'sblm': 63, 'lahir': 64, 'lahiran': 65, 'trs': 66, 'baby': 67, 'nicu': 68, 'segi': 69, 'ragu': 70, 'cmn': 71, 'residen': 72, 'yg': 73, 'jaga': 74, 'kurang': 75, 'informatif': 76, 'kasi': 77, 'penjelasan': 78, 'elit': 79, 'basement': 80, 'sulit': 81, 'ambil': 82, 'karcis': 83, 'parkirnya': 84, 'ngehalangi': 85, 'cuma': 86, 'diplang': 87, 'keluar': 88, 'bagi': 89, 'bedah': 90, 'agustus': 91, 'pebruari': 92, 'merasakan': 93, 'kenyamananketenangan': 94, 'bahagia': 95, 'itu': 96, 'berkat': 97, 'penilaian': 98, 'dah': 99, 'tes': 100, 'napza': 101, 'disini': 102, 'udah': 103, 'selesai': 104, 'tinggal': 105, 'nunggu': 106, 'hasil': 107, 'lama': 108, 'realitanya': 109, 'kelar': 110, 'anjir': 111, 'very': 112, 'waste': 113, 'of': 114, 'time': 115, 'telah': 116, 'beroperasinya': 117, 'kia': 118, 'semoga': 119, 'terbaik': 120, 'peningkatan': 121, 'ibu': 122, 'bali': 123, 'sekitarnya': 124, 'bagus': 125, 'dokternya': 126, 'kita': 127, 'lebih': 128, 'bersabar': 129, 'pasiennya': 130, 'lumayan': 131, 'buruk': 132, 'sekali': 133, 'pindah': 134, 'diperbaiki': 135, 'tanya': 136, 'sopan': 137, 'santunnya': 138, 'jutek': 139, 'ketus': 140, 'staff': 141, 'register': 142, 'sempetnya': 143, 'main': 144, 'game': 145, 'sadar': 146, 'pbi': 147, 'tapi': 148, 'sanggup': 149, 'kalau': 150, 'dianggap': 151, 'benalu': 152, 'dirujuk': 153, 'faskes': 154, 'type': 155, 'c': 156, 'ber': 157, 'monitor': 158, 'folded': 159, 'hands': 160, 'thumbs': 161, 'up': 162, 'light': 163, 'skin': 164, 'tone': 165, 'kamar': 166, 'tersedia': 167, 'memiliki': 168, 'hotel': 169, 'setiap': 170, 'layanan': 171, 'lantai': 172, 'mandi': 173, 'cukup': 174, 'pintu': 175, 'menggunakan': 176, 'rumah': 177, 'sakit': 178, 'tempat': 179, 'area': 180, 'hari': 181, 'malam': 182, 'dilengkapi': 183, 'dua': 184, 'dalam': 185, 'meja': 186, 'tidur': 187, 'lift': 188, 'berada': 189, 'resepsionis': 190, 'menyediakan': 191, 'pukul': 192, 'tamu': 193, 'lampu': 194, 'pagi': 195, 'waktu': 196, 'sistem': 197, 'sesuai': 198, 'dilakukan': 199, 'disediakan': 200, 'jendela': 201, 'standar': 202, 'kecil': 203, 'tambahan': 204, 'checkin': 205, 'umum': 206, 'lorong': 207, 'satu': 208, 'khusus': 209, 'ruangan': 210, 'bisa': 211, 'dekat': 212, 'jadwal': 213, 'sarapan': 214, 'arah': 215, 'masuk': 216, 'tirai': 217, 'kunci': 218, 'air': 219, 'terdapat': 220, 'lemari': 221, 'handuk': 222, 'utama': 223, 'kursi': 224, 'dinding': 225, 'tunggu': 226, 'ini': 227, 'medis': 228, 'televisi': 229, 'pusat': 230, 'selama': 231, 'mulai': 232, 'dibuka': 233, 'sekitar': 234, 'hingga': 235, 'tv': 236, 'secara': 237, 'baik': 238, 'kerja': 239, 'jarak': 240, 'cermin': 241, 'besar': 242, 'keamanan': 243, 'terletak': 244, 'ventilasi': 245, 'operasional': 246, 'toilet': 247, 'dasar': 248, 'tangga': 249, 'darurat': 250, 'menghadap': 251, 'langsung': 252, 'ranjang': 253, 'atau': 254, 'kolam': 255, 'renang': 256, 'merokok': 257, 'petunjuk': 258, 'saluran': 259, 'lokal': 260, 'seragam': 261, 'sebagian': 262, 'sampah': 263, 'digunakan': 264, 'karpet': 265, 'buka': 266, 'sore': 267, 'dibersihkan': 268, 'sebelum': 269, 'akses': 270, 'terbuat': 271, 'pengunjung': 272, 'identitas': 273, 'kipas': 274, 'belakang': 275, 'tanpa': 276, 'barang': 277, 'tertentu': 278, 'unit': 279, 'konsultasi': 280, 'lokasi': 281, 'ukuran': 282, 'wifi': 283, 'restoran': 284, 'proses': 285, 'checkout': 286, 'berfungsi': 287, 'keramik': 288, 'berlaku': 289, 'kota': 290, 'anakanak': 291, 'listrik': 292, 'antarjemput': 293, 'tenang': 294, 'menutupi': 295, 'selimut': 296, 'bantal': 297, 'telepon': 298, 'memakai': 299, 'sabun': 300, 'tiga': 301, 'layar': 302, 'lobi': 303, 'tanda': 304, 'berwarna': 305, 'samping': 306, 'makan': 307, 'siang': 308, 'dilapisi': 309, 'plastik': 310, 'menerima': 311, 'dispenser': 312, 'pemandangan': 313, 'saklar': 314, 'nomor': 315, 'dibatasi': 316, 'membersihkan': 317, 'kendaraan': 318, 'ujung': 319, 'menyala': 320, 'terbuka': 321, 'terlalu': 322, 'gantungan': 323, 'dekorasi': 324, 'setelah': 325, 'luas': 326, 'terdiri': 327, 'oleh': 328, 'kartu': 329, 'pemeriksaan': 330, 'digital': 331, 'antrean': 332, 'keluarga': 333, 'disesuaikan': 334, 'rutin': 335, 'tindakan': 336, 'perbelanjaan': 337, 'panas': 338, 'pakaian': 339, 'perlengkapan': 340, 'bandara': 341, 'menginap': 342, 'licin': 343, 'aman': 344, 'penerangan': 345, 'soket': 346, 'minibar': 347, 'balkon': 348, 'berjaga': 349, 'menampilkan': 350, 'jumlah': 351, 'pengering': 352, 'rambut': 353, 'permintaan': 354, 'laundry': 355, 'suara': 356, 'halaman': 357, 'depan': 358, 'dikunci': 359, 'datar': 360, 'pencahayaan': 361, 'diganti': 362, 'menu': 363, 'tetap': 364, 'berisik': 365, 'pada': 366, 'kaca': 367, 'koneksi': 368, 'rak': 369, 'dapur': 370, 'tergantung': 371, 'siaran': 372, 'sudut': 373, 'antar': 374, 'makanan': 375, 'rooftop': 376, 'alarm': 377, 'kebakaran': 378, 'papan': 379, 'kayu': 380, 'ubin': 381, 'komputer': 382, 'bekerja': 383, 'tanaman': 384, 'diatur': 385, 'wisata': 386, 'otomatis': 387, 'penyewaan': 388, 'angin': 389, 'tisu': 390, 'mendapat': 391, 'tipe': 392, 'penunjuk': 393, 'namun': 394, 'panggilan': 395, 'netral': 396, 'shower': 397, 'evakuasi': 398, 'tertempel': 399, 'kelambu': 400, 'kopi': 401, 'wastafel': 402, 'jauh': 403, 'stop': 404, 'kontak': 405, 'terang': 406, 'diminta': 407, 'sekat': 408, 'tengah': 409, 'internal': 410, 'mencatat': 411, 'berkala': 412, 'alami': 413, 'pemisah': 414, 'pendingin': 415, 'melayani': 416, 'service': 417, 'kunjungan': 418, 'tiap': 419, 'melalui': 420, 'mendapatkan': 421, 'pribadi': 422, 'spesialis': 423, 'prosedur': 424, 'wajib': 425, 'dokumen': 426, 'diakses': 427, 'ambulans': 428, 'jalur': 429, 'online': 430, 'bpjs': 431, 'inap': 432, 'dirawat': 433, 'berdasarkan': 434, 'perawatan': 435, 'darah': 436, 'operasi': 437, 'deskripsi': 438, 'single': 439, 'seluruh': 440, 'disajikan': 441, 'memakan': 442, 'minum': 443, 'gratis': 444, 'kebijakan': 445, 'berkendara': 446, 'internasional': 447, 'mandiri': 448, 'terawat': 449, 'padam': 450, 'terdengar': 451, 'bising': 452, 'mengalir': 453, 'lancar': 454, 'led': 455, 'penyimpanan': 456, 'cctv': 457, 'titik': 458, 'sinyal': 459, 'stabil': 460, 'sprei': 461, 'kapan': 462, 'mineral': 463, 'hangat': 464, 'sandal': 465, 'per': 466, 'peta': 467, 'microwave': 468, 'biru': 469, 'dimulai': 470, 'jasa': 471, 'sewa': 472, 'mobil': 473, 'berhenti': 474, 'buram': 475, 'terminal': 476, 'lan': 477, 'bantuan': 478, 'bagasi': 479, 'sepatu': 480, 'kalender': 481, 'gym': 482, 'hewan': 483, 'peliharaan': 484, 'pesan': 485, 'dikendalikan': 486, 'kamera': 487, 'terhubung': 488, 'berbahan': 489, 'beton': 490, 'vegetarian': 491, 'daftar': 492, 'penting': 493, 'pembayaran': 494, 'tunai': 495, 'transfer': 496, 'kebersihan': 497, 'hias': 498, 'jangan': 499, 'ganggu': 500, 'botol': 501, 'sampo': 502, 'harus': 503, 'menunjukkan': 504, 'remote': 505, 'manual': 506, 'jenis': 507, 'deluxe': 508, 'sepeda': 509, 'fleksibel': 510, 'kesepakatan': 511, 'baca': 512, 'cepat': 513, 'tercantum': 514, 'kabel': 515, 'bangun': 516, 'buku': 517, 'tertera': 518, 'langitlangit': 519, 'bathtub': 520, 'pengatur': 521, 'suhu': 522, 'mengenai': 523, 'baju': 524, 'galon': 525, 'lukisan': 526, 'pesanan': 527, 'terpisah': 528, 'pembuat': 529, 'bahan': 530, 'lapis': 531, 'prasmanan': 532, 'kecuali': 533, 'kulkas': 534, 'mini': 535, 'penuh': 536, 'pergi': 537, 'terkunci': 538, 'flush': 539, 'bunga': 540, 'minuman': 541, 'datang': 542, 'koper': 543, 'konvensional': 544, 'pijat': 545, 'mode': 546, 'pemanas': 547, 'batas': 548, 'jika': 549, 'basah': 550, 'kotak': 551, 'brosur': 552, 'elektronik': 553, 'antara': 554, 'cair': 555, 'batang': 556, 'kebugaran': 557, 'ditentukan': 558, 'bangunan': 559, 'lain': 560, 'meletakkan': 561, 'normal': 562, 'bersebelahan': 563, 'hiasan': 564, 'rias': 565, 'data': 566, 'diberikan': 567, 'digulung': 568, 'rapi': 569, 'spa': 570, 'membantu': 571, 'terbatas': 572, 'speaker': 573, 'radio': 574, 'rapat': 575, 'dewasa': 576, 'toko': 577, 'oleholeh': 578, 'bersama': 579, 'pembatas': 580, 'tertata': 581, 'awal': 582, 'sebelah': 583, 'dinyalakan': 584, 'menangkap': 585, 'teh': 586, 'bermain': 587, 'raya': 588, 'laut': 589, 'pengaman': 590, 'digantung': 591, 'concierge': 592, 'kedap': 593, 'gantung': 594, 'bertugas': 595, 'harian': 596, 'menuju': 597, 'landai': 598, 'pengharum': 599, 'bawah': 600, 'vip': 601, 'sumber': 602, 'cahaya': 603, 'koridor': 604, 'room': 605, 'tebal': 606, 'penitipan': 607, 'ditetapkan': 608, 'pihak': 609, 'administrasi': 610, 'bangunannya': 611, 'lobby': 612, 'seperti': 613, 'pendaftaran': 614, 'loket': 615, 'aplikasi': 616, 'kantin': 617, 'berbasis': 618, 'termasuk': 619, 'akhir': 620, 'pekan': 621, 'farmasi': 622, 'icu': 623, 'dikunjungi': 624, 'masker': 625, 'ibadah': 626, 'disimpan': 627, 'transportasi': 628, 'jemput': 629, 'dibutuhkan': 630, 'registrasi': 631, 'menyusui': 632, 'disabilitas': 633, 'laboratorium': 634, 'rujukan': 635, 'diberi': 636, 'label': 637, 'kebutuhan': 638, 'vaksinasi': 639, 'divisi': 640, 'kali': 641, 'sehari': 642, 'mesin': 643, 'atm': 644, 'tagihan': 645, 'didapat': 646, 'kasir': 647, 'pemadam': 648, 'alatalat': 649, 'gawat': 650, 'urut': 651, 'asuransi': 652, 'lingkungan': 653, 'ramai': 654, 'gizi': 655, 'diet': 656, 'minggu': 657, 'dipantau': 658, 'lewat': 659, 'rehabilitasi': 660, 'luka': 661, 'minor': 662, 'membawa': 663, 'sebelumnya': 664, 'pengambilan': 665, 'obat': 666, 'apotek': 667, 'loker': 668, 'menyimpan': 669, 'gelang': 670, 'majalah': 671, 'koran': 672, 'mahasiswa': 673, 'magang': 674, 'diperoleh': 675, 'customer': 676, 'siap': 677, 'siaga': 678, 'berpuasa': 679, 'periksa': 680, 'peralatan': 681, 'mengikuti': 682, 'pelatihan': 683, 'meminta': 684, 'ringkasan': 685, 'bersifat': 686, 'berac': 687, 'berobat': 688, 'alur': 689, 'terpampang': 690, 'fisioterapi': 691, 'menjalani': 692, 'akreditasi': 693, 'berubah': 694, 'sewaktuwaktu': 695, 'mri': 696, 'ct': 697, 'scan': 698, 'boleh': 699, 'ditemani': 700, 'donor': 701, 'id': 702, 'card': 703, 'rekam': 704, 'jantung': 705, 'transfusi': 706, 'prioritas': 707, 'sop': 708, 'alat': 709, 'disterilkan': 710, 'dilarang': 711, 'dijaga': 712, 'kerahasiaannya': 713, 'golongan': 714, 'usia': 715, 'pemulihan': 716, 'pasca': 717, 'mengisi': 718, 'form': 719, 'kepuasan': 720}\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Index:\", tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d79496c-e90d-4d08-883f-b917a004aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape TF-IDF Matrix: (3461, 2350)\n",
      "Kata-kata dalam TF-IDF: ['ac' 'ac dan' 'ac dengan' 'ac di' 'ac tidak' 'ada' 'ada ac' 'ada akses'\n",
      " 'ada alarm' 'ada dapur' 'ada dekorasi' 'ada dispenser' 'ada fasilitas'\n",
      " 'ada hiasan' 'ada jam' 'ada jendela' 'ada kalender' 'ada kamera'\n",
      " 'ada kolam' 'ada layanan' 'ada lukisan' 'ada meja' 'ada pengharum'\n",
      " 'ada ramah' 'ada ruang' 'ada sistem' 'ada tangga' 'ada tempat' 'ada unit'\n",
      " 'ada yang' 'administrasi' 'administrasi cukup' 'agustus' 'agustus sampai'\n",
      " 'air' 'air galon' 'air hangat' 'air mengalir' 'air mineral' 'air minum'\n",
      " 'air panas' 'akhir' 'akhir pekan' 'akreditasi' 'akreditasi rutin' 'akses'\n",
      " 'akses balkon' 'akses lift' 'alami' 'alami yang']\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=1, max_df=0.95,ngram_range=(1,2))  \n",
    "X_tfidf = tfidf_vectorizer.fit_transform(rs[\"Ulasan_Clean\"])\n",
    "\n",
    "# Cek ukuran data\n",
    "print(\"Shape TF-IDF Matrix:\", X_tfidf.shape)\n",
    "print(\"Kata-kata dalam TF-IDF:\", tfidf_vectorizer.get_feature_names_out()[:50])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a2b4aa0-682b-4154-ba2d-40ea62d2623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape TF-IDF Matrix: (3461, 2350)\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = tfidf_vectorizer.fit_transform(rs[\"Ulasan_Clean\"])\n",
    "print(\"Shape TF-IDF Matrix:\", X_tfidf.shape)\n",
    "y = rs[\"Sentimen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424b26d-3e6d-453e-9390-eb3bf6b8bce7",
   "metadata": {},
   "source": [
    "# **6. Pelatihan machine learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f12cd3a3-966e-4bcf-ba60-5f7eac0a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembagian data 80/20 dan 70/30\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e314e33-2c2f-481f-9040-2141a236476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Random Forest (80/20) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.89      1.00      0.94       265\n",
      "      Netral       1.00      0.60      0.75       147\n",
      "     Positif       0.92      1.00      0.96       281\n",
      "\n",
      "    accuracy                           0.91       693\n",
      "   macro avg       0.93      0.87      0.88       693\n",
      "weighted avg       0.92      0.91      0.91       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Skema 1: Random Forest dengan split 80/20\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_80, y_train_80)\n",
    "y_pred_rf = model_rf.predict(X_test_80)\n",
    "print(\"\\n🎯 Random Forest (80/20) Classification Report:\")\n",
    "print(classification_report(y_test_80, y_pred_rf, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33a64e9e-e651-49c8-a6e9-2174cca883c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 SVM (70/30) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.89      1.00      0.94       388\n",
      "      Netral       1.00      0.59      0.74       234\n",
      "     Positif       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.91      1039\n",
      "   macro avg       0.93      0.86      0.87      1039\n",
      "weighted avg       0.92      0.91      0.90      1039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Skema 2: SVM dengan split 70/30\n",
    "model_svm = SVC(kernel='linear', probability=True)\n",
    "model_svm.fit(X_train_70, y_train_70)\n",
    "y_pred_svm = model_svm.predict(X_test_70)\n",
    "print(\"\\n🎯 SVM (70/30) Classification Report:\")\n",
    "print(classification_report(y_test_70, y_pred_svm, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0041078-862d-4744-b9f8-36c21f19ba2c",
   "metadata": {},
   "source": [
    "# **7. Pelatihan model deep learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01baaeeb-3206-45e4-bd5c-b63eb7004bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping dari sebelumnya\n",
    "label_mapping = {'Negatif': 0, 'Netral': 1, 'Positif': 2}\n",
    "labels = rs[\"Sentimen\"].map(label_mapping).values\n",
    "labels_encoded = to_categorical(labels, num_classes=3).astype(\"float32\")\n",
    "\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n",
    "    padded_sequences, labels_encoded, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a35e2df-0e96-49ab-94fa-7be0d4858719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 50, 128)           640000    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 50, 64)            49408     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 50, 64)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722627 (2.76 MB)\n",
      "Trainable params: 722627 (2.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 17s 93ms/step - loss: 0.7331 - accuracy: 0.6644 - val_loss: 0.4699 - val_accuracy: 0.9242\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 5s 66ms/step - loss: 0.3473 - accuracy: 0.8966 - val_loss: 0.2667 - val_accuracy: 0.9242\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.3055 - accuracy: 0.9101 - val_loss: 0.2596 - val_accuracy: 0.9242\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.3014 - accuracy: 0.9101 - val_loss: 0.2593 - val_accuracy: 0.9242\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.3027 - accuracy: 0.9101 - val_loss: 0.2590 - val_accuracy: 0.9242\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.3013 - accuracy: 0.9101 - val_loss: 0.2649 - val_accuracy: 0.9242\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.2974 - accuracy: 0.9101 - val_loss: 0.2576 - val_accuracy: 0.9242\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.2966 - accuracy: 0.9101 - val_loss: 0.2601 - val_accuracy: 0.9242\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.2962 - accuracy: 0.9101 - val_loss: 0.2590 - val_accuracy: 0.9242\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.2968 - accuracy: 0.9101 - val_loss: 0.2585 - val_accuracy: 0.9242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x205c690ced0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=50),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_lstm.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_lstm.summary()\n",
    "y_int = rs[\"Sentimen\"].map(label_mapping).values\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_int), y=y_int)\n",
    "\n",
    "# Training\n",
    "model_lstm.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "535876fa-3fe4-40d6-8ee7-e642685fe3f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 20ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.89      1.00      0.94       265\n",
      "      Netral       1.00      0.60      0.75       147\n",
      "     Positif       0.92      1.00      0.96       281\n",
      "\n",
      "    accuracy                           0.91       693\n",
      "   macro avg       0.93      0.87      0.88       693\n",
      "weighted avg       0.92      0.91      0.91       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(X_test_lstm)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test_lstm, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_labels, target_names=[\"Negatif\", \"Netral\", \"Positif\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9920d316-7dcd-4435-b340-2f7cd41f86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, tokenizer, model, max_length=50, threshold=0.5):\n",
    "    # Step 1: Bersihkan teks\n",
    "    text_clean = clean_text(text)\n",
    "    \n",
    "    # Step 2: Tokenisasi & Padding\n",
    "    seq = tokenizer.texts_to_sequences([text_clean])\n",
    "    \n",
    "    if len(seq[0]) == 0:\n",
    "        return \"Teks tidak dikenali oleh model (hasil tokenisasi kosong).\"\n",
    "    \n",
    "    pad_seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    \n",
    "    # Step 3: Prediksi\n",
    "    pred = model.predict(pad_seq, verbose=0)\n",
    "    label_index = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    # Step 4: Mapping label\n",
    "    reverse_label_mapping = {0: \"Negatif\", 1: \"Netral\", 2: \"Positif\"}\n",
    "    predicted_label = reverse_label_mapping[label_index]\n",
    "\n",
    "    # Step 5: Output + Confidence Check\n",
    "    if confidence < threshold:\n",
    "        return f\"Model kurang yakin (confidence: {confidence:.2f}). Prediksi: {predicted_label}\"\n",
    "    else:\n",
    "        return f\"{predicted_label} (confidence: {confidence:.2f})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "522196cf-415a-440e-8a1c-ee6eb46744ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positif (confidence: 0.91)'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"pelayanan bagus staf dan dokternya ramah\", tokenizer, model_lstm)\n",
    "# Output: Positif \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e869d7b-2001-4000-9e77-05aac3e3866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Netral (confidence: 1.00)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"Tidak tersedia layanan antar-jemput\", tokenizer, model_lstm)\n",
    "# Output: Netral \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3881c48b-33ea-49b8-8028-71bfcf6dbaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negatif (confidence: 0.92)'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"tidak ada ramah sopan santunnya jutek ketus dan staff di bagian register main game doang\", tokenizer, model_lstm)\n",
    "# Output: Negatif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea5ea3-996e-4e5a-966a-1213ddad498d",
   "metadata": {},
   "source": [
    "# **8. Export pkl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45de511c-fbd2-4f08-909c-7fffc47b835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771f59e-3168-4019-8db8-5f324be16307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
